{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeenPeil Monitor: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en_US.UTF-8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import locale\n",
    "import time\n",
    "locale.setlocale(locale.LC_ALL, '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the data in a dictionary\n",
    "tweetsFile = open('data-17_03_2016.json')\n",
    "tweetsString = tweetsFile.read()\n",
    "tweets = json.loads(tweetsString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'favorite_count': 0, 'created_at': 'Thu Feb 25 10:15:30 +0000 2016', 'is_quote_status': False, 'contributors': None, 'in_reply_to_user_id_str': '371932423', 'retweeted': False, 'user': {'id': 3576975202, 'time_zone': 'Pacific Time (US & Canada)', 'name': 'Valentino-v.Gogh', 'following': None, 'notifications': None, 'screen_name': 'Backenricker', 'profile_sidebar_fill_color': '000000', 'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/657929087252627456/kPGzL3vR.jpg', 'profile_use_background_image': True, 'profile_text_color': '000000', 'verified': False, 'created_at': 'Mon Sep 07 12:39:34 +0000 2015', 'followers_count': 1389, 'listed_count': 335, 'statuses_count': 25393, 'description': 'Art Music Science Maths Physics QM Tech HR Humanity Nature. T mostly Dutch. ★ Blackstar, Shining, UFO collector(7). Quarky. RT/... not endorsement', 'follow_request_sent': None, 'default_profile': False, 'geo_enabled': False, 'profile_sidebar_border_color': '000000', 'favourites_count': 4824, 'friends_count': 4996, 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/3576975202/1445599824', 'profile_link_color': '9266CC', 'utc_offset': -28800, 'url': 'https://www.youtube.com/watch?v=ynCcR99zYU4', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/686628294217760768/AWJ4Y-X6_normal.png', 'profile_background_tile': True, 'is_translator': False, 'id_str': '3576975202', 'profile_background_color': '000000', 'profile_image_url': 'http://pbs.twimg.com/profile_images/686628294217760768/AWJ4Y-X6_normal.png', 'contributors_enabled': False, 'protected': False, 'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/657929087252627456/kPGzL3vR.jpg', 'location': 'Villa of Ormen, Netherlands', 'lang': 'en', 'default_profile_image': False}, 'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>', 'truncated': False, 'entities': {'user_mentions': [{'indices': [0, 14], 'screen_name': 'AdriaanBeenen', 'id': 371932423, 'id_str': '371932423', 'name': 'Adriaan Beenen'}, {'indices': [15, 30], 'screen_name': 'BenjoHilbrink1', 'id': 889712592, 'id_str': '889712592', 'name': 'Benjo Hilbrink'}], 'media': [{'id': 702799068829872133, 'media_url_https': 'https://pbs.twimg.com/media/CcDYB44UcAUUaYv.png', 'id_str': '702799068829872133', 'indices': [105, 128], 'display_url': 'pic.twitter.com/rFsetsdR5w', 'sizes': {'large': {'w': 495, 'resize': 'fit', 'h': 674}, 'thumb': {'w': 150, 'resize': 'crop', 'h': 150}, 'small': {'w': 495, 'resize': 'fit', 'h': 674}, 'medium': {'w': 495, 'resize': 'fit', 'h': 674}}, 'type': 'photo', 'expanded_url': 'http://twitter.com/Backenricker/status/702799069832466432/photo/1', 'media_url': 'http://pbs.twimg.com/media/CcDYB44UcAUUaYv.png', 'url': 'https://t.co/rFsetsdR5w'}], 'symbols': [], 'hashtags': [{'text': 'GeenPeil', 'indices': [95, 104]}], 'urls': [{'display_url': 'geenstijl.nl/mt/archieven/2…', 'expanded_url': 'http://www.geenstijl.nl/mt/archieven/2016/02/geen_miljard_sorosdollars_die_dit_recht_gaan_praten.html', 'indices': [71, 94], 'url': 'https://t.co/DmoG2jFWP4'}]}, 'id': 702799069832466432, 'possibly_sensitive': False, 'timestamp_ms': '1456395330280', 'retweet_count': 0, 'in_reply_to_status_id': 702525968070610945, 'place': None, 'in_reply_to_user_id': 371932423, 'in_reply_to_screen_name': 'AdriaanBeenen', 'filter_level': 'low', 'id_str': '702799069832466432', 'geo': None, 'coordinates': None, 'extended_entities': {'media': [{'id': 702799068829872133, 'media_url_https': 'https://pbs.twimg.com/media/CcDYB44UcAUUaYv.png', 'id_str': '702799068829872133', 'indices': [105, 128], 'display_url': 'pic.twitter.com/rFsetsdR5w', 'sizes': {'large': {'w': 495, 'resize': 'fit', 'h': 674}, 'thumb': {'w': 150, 'resize': 'crop', 'h': 150}, 'small': {'w': 495, 'resize': 'fit', 'h': 674}, 'medium': {'w': 495, 'resize': 'fit', 'h': 674}}, 'type': 'photo', 'expanded_url': 'http://twitter.com/Backenricker/status/702799069832466432/photo/1', 'media_url': 'http://pbs.twimg.com/media/CcDYB44UcAUUaYv.png', 'url': 'https://t.co/rFsetsdR5w'}]}, 'text': '@AdriaanBeenen @BenjoHilbrink1 \\nWaarnemers van de OVSE bijvoorbeeld...\\nhttps://t.co/DmoG2jFWP4\\n#GeenPeil https://t.co/rFsetsdR5w', 'favorited': False, 'lang': 'nl', 'in_reply_to_status_id_str': '702525968070610945'}\n"
     ]
    }
   ],
   "source": [
    "# How does a tweet look?\n",
    "print(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linksCounter = Counter()\n",
    "for i in range(0,len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    entities = tweet['entities']\n",
    "    urls = entities['urls']\n",
    "    for j in range(0,len(urls)):\n",
    "        link = urls[j]['expanded_url']\n",
    "        linksCounter[link] += 1\n",
    "\n",
    "totalUrls = []\n",
    "\n",
    "for k,v in dict(linksCounter).items():\n",
    "    if v > 100:\n",
    "        totalUrls.append({\"url\":str(k),\"count\":v})\n",
    "\n",
    "with open(\"urls.json\", 'w') as outfile:\n",
    "    json.dump(totalUrls, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How does a tweet location look?\n",
    "locationCounter = Counter()\n",
    "\n",
    "for i in range(0,len(tweets)):\n",
    "    location = tweets[i]['user']['location']\n",
    "    locationCounter[location] += 1\n",
    "    \n",
    "print(locationCounter)\n",
    "coordsCount = 0\n",
    "for i in range(0,len(tweets)):\n",
    "    coords = tweets[i]['coordinates']\n",
    "    if coords != None:\n",
    "        coordsCount += 1\n",
    "print(coordsCount) # not even unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Which headers are in a tweet?\n",
    "print (tweets[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Which headers are in the user object?\n",
    "print (tweets[0]['user'].keys())\n",
    "\n",
    "# What is in a user?\n",
    "for i in range(0,len(tweets)):\n",
    "    if tweets[i]['user']['screen_name'] == \"VVD\":\n",
    "        print (tweets[i]['text'])\n",
    "#print (tweets[0]['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read Dutch noise words file\n",
    "noiseWords = []\n",
    "f = open('stopwoordenlijst.txt', 'r')\n",
    "for line in f:\n",
    "    word = line.rstrip()\n",
    "    noiseWords.append(word)\n",
    "print(noiseWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter uninteresting words\n",
    "import re, string \n",
    "pattern = re.compile('[^a-zA-Z]+')\n",
    "textFromTweets = []\n",
    "\n",
    "for i in range(0, len(tweets)):\n",
    "    textFromTweets.append(' '.join([pattern.sub('', word.lower()) for word in tweets[i]['text'].split() if word.lower() not in noiseWords]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# count occurences per word\n",
    "wordCounts = Counter()\n",
    "for tweet in textFromTweets:\n",
    "    words = tweet.split()\n",
    "    for word in words:\n",
    "        wordCounts[word] += 1\n",
    "\n",
    "with open(\"wordcounts.json\", 'w') as outfile:\n",
    "    json.dump(wordCounts, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count occurences per word, new format\n",
    "wordsList = []\n",
    "\n",
    "for key in wordCounts.keys():\n",
    "    wordsDict = {}\n",
    "    if wordCounts[key] > 200 and len(key) >= 2 and key not in noiseWords:\n",
    "        wordsDict.update({\"text\":key,\"size\":wordCounts[key]})\n",
    "        wordsList.append(wordsDict)\n",
    "\n",
    "\n",
    "with open(\"GeenPeilMonitor/server/public/words.json\", 'w') as outfile:\n",
    "    json.dump(wordsList, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count occurences per user and daily occurences per user\n",
    "userCounts = Counter()\n",
    "dailyUserCounts = {}\n",
    "\n",
    "for i in range(0,len(tweets)):\n",
    "    user = tweets[i]['user']['screen_name']\n",
    "    ts = time.strftime('%Y-%m-%d', time.strptime(tweets[i]['created_at'],'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "    userCounts[user] += 1\n",
    "    if ts in dailyUserCounts:\n",
    "        if user in dailyUserCounts[ts]:\n",
    "            dailyUserCounts[ts][user] += 1\n",
    "        else:\n",
    "            dailyUserCounts[ts][user] = 1\n",
    "    else:\n",
    "        dailyUserCounts.update({ts:{user: 1}})\n",
    "\n",
    "with open(\"usercounts.json\", 'w') as outfile:\n",
    "    json.dump(userCounts, outfile)\n",
    "\n",
    "    \n",
    "with open(\"dailyusercounts.json\",'w') as outfile:\n",
    "    json.dump(dailyUserCounts,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of tweets per day\n",
    "dailyCounts = Counter()\n",
    "\n",
    "for i in range(0,len(tweets)):\n",
    "    ts = time.strftime('%Y-%m-%d', time.strptime(tweets[i]['created_at'],'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "    dailyCounts[ts] += 1\n",
    "\n",
    "with open(\"dailycounts.json\", 'w') as outfile:\n",
    "    json.dump(dailyCounts, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basis for occurrences of words per day\n",
    "textFromTweetsPerDay = {}\n",
    "\n",
    "for i in range(0, len(tweets)):\n",
    "    ts = time.strftime('%Y-%m-%d', time.strptime(tweets[i]['created_at'],'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "    textFromTweetsPerDay.setdefault(ts,[]).append(' '.join([pattern.sub('',word.lower()) for word in tweets[i]['text'].split() if word.lower() not in noiseWords]))\n",
    "\n",
    "wordCountsFromTweetsPerDay = {}\n",
    "for day in textFromTweetsPerDay:\n",
    "    dailyWordCounts = {}\n",
    "    for tweet in textFromTweetsPerDay[day]:\n",
    "        words = tweet.split()\n",
    "        for word in words:\n",
    "            if word in dailyWordCounts:\n",
    "                dailyWordCounts[word] += 1\n",
    "            else:\n",
    "                dailyWordCounts[word] = 1\n",
    "    if day in wordCountsFromTweetsPerDay:\n",
    "        wordCountsFromTweetsPerDay[day]['text'] = dailyWordCounts\n",
    "    else:\n",
    "        wordCountsFromTweetsPerDay[day] = {}\n",
    "        wordCountsFromTweetsPerDay[day]['text'] = dailyWordCounts\n",
    "\n",
    "print(wordCountsFromTweetsPerDay[\"2016-02-27\"]['text'])\n",
    "    \n",
    "with open(\"wordcountsperday.json\", 'w') as outfile:\n",
    "    json.dump(wordCountsFromTweetsPerDay, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dailyWordsList = []\n",
    "\n",
    "for day in wordCountsFromTweetsPerDay.keys():\n",
    "    wordsDict = {}\n",
    "    wordsDict.update({\"date\":day,\"total\":dailyCounts[day],\"words\":[]})\n",
    "    for key in wordCountsFromTweetsPerDay[day]['text']:\n",
    "        if wordCountsFromTweetsPerDay[day]['text'][key] > 60 and len(key) >= 2 and key not in noiseWords:\n",
    "            wordsDict['words'].append({\"text\":key,\"size\":wordCountsFromTweetsPerDay[day]['text'][key]})\n",
    "    dailyWordsList.append(wordsDict)\n",
    "\n",
    "\n",
    "with open(\"GeenPeilMonitor/server/public/dailywords.json\", 'w') as outfile:\n",
    "    json.dump(dailyWordsList, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape json for convenience\n",
    "totalData = {}\n",
    "\n",
    "keys = wordCountsFromTweetsPerDay.keys()\n",
    "\n",
    "for key in keys:\n",
    "    totalData[key] = {'count':dailyCounts[key], 'user_counts':dailyUserCounts[key],'word_counts':wordCountsFromTweetsPerDay[key]}\n",
    "    \n",
    "with open(\"aggregatedData.json\", 'w') as outfile:\n",
    "    json.dump(totalData, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check out most common users\n",
    "print(userCounts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
